# Requirements for inference server
torch>=1.9.0
torchvision>=0.10.0
fastapi>=0.68.0
uvicorn>=0.15.0
python-multipart>=0.0.5
Pillow>=8.0.0
huggingface_hub>=0.16.0
